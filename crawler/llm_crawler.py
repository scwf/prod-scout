"""
llm_crawler.py - å¤šæºæ•°æ®æŠ“å–ä¸ä¿¡æ¯æ•´ç†å·¥å…·

åŠŸèƒ½æ¦‚è¿°ï¼š
1. RSS è®¢é˜…æŠ“å–ï¼šæ”¯æŒä» RSSHub ç­‰æºæŠ“å–æœ€æ–°æ›´æ–°ï¼ˆå¦‚ Twitter, YouTube, åšå®¢ï¼‰ã€‚
2. Web å†…å®¹æŠ“å–ï¼šä½¿ç”¨ Selenium æŠ“å–æ™®é€šç½‘é¡µå†…å®¹ã€‚
3. æ™ºèƒ½æˆªå›¾ä¸å½’æ¡£ï¼šæ”¯æŒç”Ÿæˆç½‘é¡µé•¿æˆªå›¾ (PNG) å’Œé«˜ä¿çœŸ PDF å­˜æ¡£ï¼Œè‡ªåŠ¨å¤„ç†æ‡’åŠ è½½å’Œé•¿é¡µé¢ã€‚
4. LLM æ•´ç†æ€»ç»“ï¼šè°ƒç”¨å¤§æ¨¡å‹ API å¯¹æŠ“å–å†…å®¹è¿›è¡Œç»“æ„åŒ–æ•´ç†ã€‚

è¾“å…¥ï¼š
- é…ç½®åŒºåŸŸçš„ RSS æºåˆ—è¡¨ (rss_sources)
- é…ç½®åŒºåŸŸçš„ Web URL åˆ—è¡¨ (web_sources)

è¾“å‡ºï¼š
- æ§åˆ¶å°æ‰“å°çš„ç»“æ„åŒ–æƒ…æŠ¥ç®€æŠ¥ (Markdown æ ¼å¼)
- data/ ç›®å½•ä¸‹çš„ç½‘é¡µå¿«ç…§ (PNG é•¿å›¾)
- data/ ç›®å½•ä¸‹çš„ç½‘é¡µå­˜æ¡£ (PDF)

ä¾èµ–ï¼šselenium, feedparser, openai, beautifulsoup4
"""
import feedparser
import base64
from datetime import datetime, timedelta, timezone
from dateutil import parser as date_parser
from openai import OpenAI
import os
import configparser
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time

# åŠ è½½é…ç½®æ–‡ä»¶ (config.iniï¼Œä½äºé¡¹ç›®æ ¹ç›®å½•)
config = configparser.ConfigParser()
config.read(os.path.join(os.path.dirname(__file__), '..', 'config.ini'), encoding='utf-8')

# ================= é…ç½®åŒºåŸŸ =================
# 1. è®¾ç½® LLM API (ä» config.ini é…ç½®æ–‡ä»¶è¯»å–)
client = OpenAI(
    api_key=config.get('llm', 'api_key'), 
    base_url=config.get('llm', 'base_url')  # å¦‚æœæ˜¯ç”¨ä¸­è½¬æˆ–è€…å…¶ä»–æ¨¡å‹ï¼Œä¿®æ”¹ config.ini æ–‡ä»¶
)

# 2. è®¾ç½® RSSHub çš„è®¢é˜…æº (å…³é”®æ­¥éª¤)
# æç¤ºï¼šX (Twitter) å’Œ YouTube çš„è·¯ç”±å¯ä»¥åœ¨ https://docs.rsshub.app/ æ‰¾åˆ°
rss_sources = {
    # "36Kr_News": "https://rsshub.app/36kr/newsflashes", # 36æ°ªå¿«è®¯
    # "OpenAI_Blog": "https://rsshub.app/openai/blog",    # OpenAI å®˜æ–¹åšå®¢
    # æ³¨æ„ï¼šå¾®åš/X å¯èƒ½éœ€è¦è‡ªå»º RSSHub æœåŠ¡æˆ–é…ç½® Cookie æ‰èƒ½ç¨³å®šæŠ“å–
    # "ElonMusk_X": "http://127.0.0.1:1200/twitter/user/elonmusk", 
    "è…¾è®¯æŠ€æœ¯å·¥ç¨‹": "https://wechat2rss.xlab.app/feed/9685937b45fe9c7a526dbc32e4f24ba879a65b9a.xml",
}

# 3. è®¾ç½®æ™®é€š Web URL æŠ“å–æº (æ–°å¢)
# é€‚ç”¨äºæ²¡æœ‰ RSS çš„å•é¡µé¢ï¼Œå¦‚å…·ä½“çš„ä¸€ç¯‡åšæ–‡æˆ–é™æ€é¡µé¢
web_sources = {
    # "Qwen_blog": "https://qwen.ai/research",
    # "DeepMind_About": "https://deepmind.google/about/",
}

# 3. è®¾ç½®æ—¶é—´èŒƒå›´ (æœ€è¿‘ 7 å¤©)
DAYS_LOOKBACK = 7
# ===========================================

def fetch_recent_posts(rss_url, days):
    """
    æŠ“å– RSS å¹¶ç­›é€‰æŒ‡å®šå¤©æ•°å†…çš„å†…å®¹
    """
    print(f"æ­£åœ¨æŠ“å–: {rss_url} ...")
    try:
        feed = feedparser.parse(rss_url)
        recent_posts = []
        
        # è·å–å½“å‰æ—¶é—´ (å¸¦æ—¶åŒºæ„ŸçŸ¥ï¼Œé»˜è®¤ä¸º UTC ä»¥ä¾¿æ¯”è¾ƒ)
        now = datetime.now(timezone.utc)
        
        for entry in feed.entries:
            # è§£æå‘å¸ƒæ—¶é—´
            if hasattr(entry, 'published'):
                post_date = date_parser.parse(entry.published)
            elif hasattr(entry, 'updated'):
                post_date = date_parser.parse(entry.updated)
            else:
                continue # æ²¡æœ‰æ—¶é—´æˆ³è·³è¿‡

            # ç¡®ä¿ post_date æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™è®¾ä¸º UTC
            if post_date.tzinfo is None:
                post_date = post_date.replace(tzinfo=timezone.utc)
            
            # è®¡ç®—æ—¶é—´å·®
            if (now - post_date).days <= days:
                # æ¸…æ´—æ•°æ®ï¼Œæå–æ ‡é¢˜ã€é“¾æ¥å’Œæ‘˜è¦
                content = entry.get('summary', '') or entry.get('description', '')
                # ç®€å•å»é™¤ HTML æ ‡ç­¾ (å¯é€‰ï¼ŒLLM å…¶å®èƒ½è¯»æ‡‚ HTMLï¼Œä½†çº¯æ–‡æœ¬æ›´çœ Token)
                # è¿™é‡Œç®€å•å¤„ç†ï¼Œä¿ç•™åŸå§‹æ–‡æœ¬ç»™ LLM ä¹Ÿå¯ä»¥
                
                recent_posts.append({
                    "title": entry.title,
                    "date": post_date.strftime("%Y-%m-%d"),
                    "link": entry.link,
                    "content_snippet": content[:500] # æˆªå–å‰500å­—ç¬¦é˜²æ­¢ Token æº¢å‡º
                })
                
        return recent_posts
    except Exception as e:
        print(f"æŠ“å–å¤±è´¥: {e}")
        return []

def fetch_web_content(url):
    """
    æŠ“å–æ™®é€šç½‘é¡µå†…å®¹ (ä½¿ç”¨ Selenium ä»¥æ”¯æŒåŠ¨æ€æ¸²æŸ“)
    """
    print(f"æ­£åœ¨æŠ“å–ç½‘é¡µ(Selenium): {url} ...")
    driver = None
    try:
        # é…ç½®æ— å¤´æµè§ˆå™¨
        chrome_options = Options()
        chrome_options.add_argument("--headless")  # æ— ç•Œé¢æ¨¡å¼
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        # ä¼ªè£… User-Agent
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        driver.get(url)
        # ç­‰å¾…é¡µé¢åŠ è½½ (ç®€å•ç­‰å¾…ï¼Œå¯æ”¹è¿›ä¸º WebDriverWait)
        time.sleep(5) 
        
        # è·å–æ¸²æŸ“åçš„ HTML
        html_content = driver.page_source
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # æå–æ ‡é¢˜
        title = soup.title.string.strip() if soup.title else url
        
        # æå–æ­£æ–‡ 
        # ç­–ç•¥ï¼šä¼˜å…ˆæ‰¾ article æ ‡ç­¾ï¼Œå…¶æ¬¡æ‰¾ä¸»è¦çš„ div ç±»åï¼Œæœ€åå…œåº• p æ ‡ç­¾
        content_text = ""
        
        # å°è¯•é€šå¸¸çš„æ–‡ç« å®¹å™¨
        article = soup.find('article')
        if article:
            content_text = article.get_text(strip=True)
        else:
            # å…œåº•ï¼šè·å–æ‰€æœ‰ p æ ‡ç­¾
            paragraphs = soup.find_all('p')
            content_text = "\n".join([p.get_text().strip() for p in paragraphs if p.get_text().strip()])
            
            # æœ€åçš„å…œåº•ï¼šbody
            if not content_text and soup.body:
                content_text = soup.body.get_text(strip=True)

        # DEBUG: æ‰“å°æŠ“å–åˆ°çš„å†…å®¹æ—¥å¿—
        print(f"[DEBUG] Title: {title}")
        print(f"[DEBUG] Content Length: {len(content_text)}")
        preview = content_text[:200].replace('\n', ' ')
        print(f"[DEBUG] Content Preview (first 200 chars):\n{preview}...\n")

        # æ™®é€šç½‘é¡µé€šå¸¸æ²¡æœ‰ç»Ÿä¸€çš„ "å‘å¸ƒæ—¶é—´" å…ƒæ•°æ®ï¼Œè¿™é‡Œä½¿ç”¨å½“å‰æŠ“å–æ—¶é—´ä½œä¸ºå‚è€ƒ
        pub_date = datetime.now().strftime("%Y-%m-%d")
        
        return [{
            "title": title,
            "date": pub_date,
            "link": url,
            "content_snippet": content_text[:5000] # Selenium æŠ“å–çš„å†…å®¹å¯èƒ½è¾ƒå¤šï¼Œç»™ 5000 å­—ç¬¦
        }]
    except Exception as e:
        print(f"ç½‘é¡µæŠ“å–å¤±è´¥: {e}")
        return []
    finally:
        if driver:
            driver.quit()

def _prepare_page_for_capture(url):
    """
    å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼šåˆå§‹åŒ–æµè§ˆå™¨ï¼Œæ‰“å¼€ç½‘é¡µï¼Œå¹¶æ»šåŠ¨åŠ è½½æ‰€æœ‰å†…å®¹ã€‚
    è¿”å› (driver, last_height)
    æ³¨æ„ï¼šè°ƒç”¨æ–¹è´Ÿè´£ driver.quit()
    """
    print(f"æ­£åœ¨å‡†å¤‡é¡µé¢: {url} ...")
    driver = None
    try:
        # å¤ç”¨ Selenium é…ç½®
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--disable-gpu")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--window-size=1920,1080") # è®¾ç½®åˆå§‹çª—å£å¤§å°
        chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")

        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=chrome_options)
        
        driver.get(url)
        
        # æ™ºèƒ½å¯»æ‰¾æ»šåŠ¨å®¹å™¨å¹¶è§¦å‘æ‡’åŠ è½½
        print(" -> æ­£åœ¨åˆ†æé¡µé¢ç»“æ„å¹¶åŠ è½½å†…å®¹...")
        
        # 1. æ¨¡æ‹Ÿæ»šåŠ¨ (é’ˆå¯¹æ‰¾åˆ°çš„å…ƒç´ )
        # æˆ‘ä»¬åˆ†æ®µæ»šåŠ¨ï¼Œç¡®ä¿è§¦å‘ Lazy Load
        last_height = 0
        
        # æœ€å¤šå°è¯•æ»šåŠ¨ 20 æ¬¡ï¼Œæ¯æ¬¡æ»š 1000pxï¼Œç›´åˆ°æ»šä¸åŠ¨
        for i in range(20):
            driver.execute_script("""
                let el = (function() { 
                    let maxS = 0; let target = document.documentElement;
                    [document.documentElement, document.body, ...document.querySelectorAll('div')].forEach(e => {
                        if(e.scrollHeight > maxS && e.offsetParent !== null) { maxS = e.scrollHeight; target = e; }
                    });
                    return target;
                })();
                el.scrollTop = el.scrollHeight; 
                window.scrollTo(0, document.body.scrollHeight);
            """)
            
            time.sleep(1.5) # ç­‰å¾…åŠ è½½
            
            # æ£€æŸ¥é«˜åº¦æ˜¯å¦è¿˜åœ¨å¢é•¿
            new_height = driver.execute_script("""
                let maxS = Math.max(document.body.scrollHeight, document.documentElement.scrollHeight);
                let divs = document.querySelectorAll('div');
                for(let d of divs) { if(d.scrollHeight > maxS) maxS = d.scrollHeight; }
                return maxS;
            """)
            
            if new_height == last_height and i > 2: # è‡³å°‘æ»šä¸¤æ¬¡ç¡®è®¤
                print(f" -> å†…å®¹åŠ è½½å®Œæ¯•ï¼Œæ£€æµ‹åˆ°é«˜åº¦: {new_height}px")
                break
            
            last_height = new_height
            if new_height > 30000:
                print(" -> é¡µé¢è¿‡é•¿ï¼Œæå‰åœæ­¢")
                break
                
        # æ»šå›é¡¶éƒ¨
        driver.execute_script("window.scrollTo(0, 0)")
        return driver, last_height

    except Exception as e:
        print(f"é¡µé¢å‡†å¤‡å¤±è´¥: {e}")
        if driver:
            driver.quit()
        return None, 0

def capture_web_screenshot_png(url, output_path):
    """
    æŠ“å–ç½‘é¡µé•¿æˆªå›¾ (PNG)
    """
    print(f"æ­£åœ¨ç”Ÿæˆ PNG: {url} ...")
    driver, last_height = _prepare_page_for_capture(url)
    if not driver:
        return False
        
    try:
        # æˆªå›¾: è®¾ç½®çª—å£ä¸ºæœ€å¤§æ£€æµ‹åˆ°çš„é«˜åº¦ + ç¼“å†²
        final_height = last_height + 200
        if final_height > 30000: final_height = 30000
        if final_height < 1080: final_height = 1080 # ä¿åº•
        
        print(f"Final Viewport Height: {final_height}px")
        driver.set_window_size(1920, final_height)
        time.sleep(2) # å¸ƒå±€é‡ç»˜ç­‰å¾…
        driver.save_screenshot(output_path)
        print(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
        return True
    except Exception as e:
        print(f"PNG ç”Ÿæˆå¤±è´¥: {e}")
        return False
    finally:
        driver.quit()

def capture_web_pdf(url, output_path):
    """
    æŠ“å–ç½‘é¡µå¹¶å¯¼å‡ºä¸ºå•é¡µé•¿ PDF
    """
    print(f"æ­£åœ¨ç”Ÿæˆ PDF: {url} ...")
    driver, last_height = _prepare_page_for_capture(url)
    if not driver:
        return False

    try:
        # PDF ä¿®å¤é€»è¾‘ï¼š
        # ç›´æ¥ä½¿ç”¨åˆšæ‰æ»šåŠ¨æ¢æµ‹åˆ°çš„çœŸå®é«˜åº¦ (last_height)
        real_height = max(last_height, 1080)
        
        driver.execute_script(f"""
            // 1. å°è¯•æ‰¾åˆ°é‚£ä¸ªæ»šåŠ¨å®¹å™¨
            let scrollEl = (function() {{ 
                let maxS = 0; let target = document.body;
                [document.documentElement, document.body, ...document.querySelectorAll('div')].forEach(e => {{
                    if(e.scrollHeight > maxS && e.offsetParent !== null) {{ maxS = e.scrollHeight; target = e; }}
                }});
                return target;
            }})();
            
            // 2. æš´åŠ›æ’‘å¼€
            let h = '{real_height}px';
            
            if(scrollEl) {{
                scrollEl.style.height = h;
                scrollEl.style.maxHeight = 'none';
                scrollEl.style.overflow = 'visible';
            }}
            document.body.style.height = h;
            document.documentElement.style.height = h;
            document.body.style.overflow = 'visible';
            document.documentElement.style.overflow = 'visible';
        """)
        time.sleep(1) # ç­‰å¾…æ¸²æŸ“æ›´æ–°

        # è®¡ç®—å°ºå¯¸
        metrics = driver.execute_script("return { width: Math.max(document.body.scrollWidth, document.documentElement.scrollWidth, 1200) }")
        page_width_in_inches = metrics['width'] / 96.0
        page_height_in_inches = (real_height + 100) / 96.0 
        
        print(f" -> ç”Ÿæˆ PDF å°ºå¯¸: {metrics['width']}x{real_height} px (ç”±æ»šåŠ¨æ¢æµ‹å†³å®š)")

        params = {
            'landscape': False,
            'displayHeaderFooter': False,
            'printBackground': True,
            'preferCSSPageSize': False,
            'paperWidth': page_width_in_inches,
            'paperHeight': page_height_in_inches,
            'marginTop': 0,
            'marginBottom': 0,
            'marginLeft': 0,
            'marginRight': 0,
        }
        
        result = driver.execute_cdp_cmd("Page.printToPDF", params)
        with open(output_path, 'wb') as f:
            f.write(base64.b64decode(result['data']))
        print(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {output_path}")
        return True
    except Exception as e:
        print(f"PDF ç”Ÿæˆå¤±è´¥: {e}")
        return False
    finally:
        driver.quit()


def organize_data(posts, source_name):
    """
    è°ƒç”¨ LLM å¯¹ä¿¡æ¯è¿›è¡Œæ ‡å‡†åŒ–æ•´ç† (æ—¶é—´ã€äº‹ä»¶ç»´åº¦)
    """
    if not posts:
        return f"ã€{source_name}ã€‘æœ€è¿‘ {DAYS_LOOKBACK} å¤©æ²¡æœ‰æ›´æ–°ã€‚"

    # æ„å»º Prompt
    data_text = ""
    for idx, post in enumerate(posts):
        # æˆªå–ä¸€éƒ¨åˆ†å†…å®¹ï¼Œé¿å… Token è¿‡é•¿ï¼Œä½†è¦è¶³å¤Ÿæå–ä¿¡æ¯
        snippet = post['content_snippet'][:1000]
        data_text += f"ID: {idx+1}\næ ‡é¢˜: {post['title']}\næ—¶é—´: {post['date']}\nå†…å®¹: {snippet}\n\n"

    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ•´ç†åŠ©æ‰‹ã€‚è¯·å¯¹ä»¥ä¸‹æ¥è‡ªã€{source_name}ã€‘çš„åŸå§‹æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–æ•´ç†ã€‚
    
    ç›®æ ‡ï¼š
    ä¸è¦ç”Ÿæˆç¬¼ç»Ÿçš„æ€»ç»“æŠ¥å‘Šã€‚è¯·æŒ‰ç…§â€œæ—¶é—´â€å’Œâ€œäº‹ä»¶â€ç»´åº¦ï¼Œå°†æ¯æ¡æœ‰ä»·å€¼çš„ä¿¡æ¯ç»“æ„åŒ–å±•ç¤ºå’Œè¾“å‡ºã€‚
    
    è¦æ±‚ï¼š
    1. æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨æœ€å‰ï¼‰ã€‚
    2. æ¯ä¸€é¡¹éœ€åŒ…å«ï¼š
       - **æ—¥æœŸ**: YYYY-MM-DD
       - **äº‹ä»¶**: ç®€ç»ƒæ¦‚æ‹¬å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆæ ‡é¢˜/æ ¸å¿ƒåŠ¨ä½œï¼‰
       - **å…³é”®ä¿¡æ¯**: æå– 1-3 ç‚¹æ ¸å¿ƒç»†èŠ‚ï¼ˆå¦‚å‘å¸ƒäº†ä»€ä¹ˆæ¨¡å‹ã€å…·ä½“å‚æ•°ã€æ´»åŠ¨åœ°ç‚¹ç­‰ï¼‰
       - **åˆ†ç±»**: ç»™è¯¥äº‹ä»¶æ‰“ä¸€ä¸ªæ ‡ç­¾ï¼ˆå¦‚ï¼šæŠ€æœ¯å‘å¸ƒã€å•†ä¸šåŠ¨æ€ã€è§‚ç‚¹åˆ†äº«ã€å…¶ä»–ï¼‰
    3. å¿½ç•¥æ— å®è´¨å†…å®¹çš„æ¡ç›®ï¼ˆå¦‚çº¯å¹¿å‘Šæˆ–æ— æ„ä¹‰çš„çŸ­æ–‡ï¼‰ã€‚
    4. è¾“å‡ºæ ¼å¼è¯·ä½¿ç”¨ Markdown åˆ—è¡¨æˆ–è¡¨æ ¼ï¼Œä¿æŒæ¸…æ™°ã€‚

    å¾…æ•´ç†æ•°æ®ï¼š
    {data_text}
    """

    response = client.chat.completions.create(
        model=config.get('llm', 'model'),  # æ¨¡å‹åç§°ä» config.ini è¯»å–
        messages=[
            {"role": "system", "content": "You are a helpful assistant for data organization."},
            {"role": "user", "content": prompt}
        ]
    )
    
    return response.choices[0].message.content

# ================= ä¸»ç¨‹åºå…¥å£ =================
if __name__ == "__main__":
    final_report = "# ğŸŒ å…¨çƒæƒ…æŠ¥å‘¨æŠ¥ (Automated)\n\n"
    
    for name, url in rss_sources.items():
        posts = fetch_recent_posts(url, DAYS_LOOKBACK)
        print(f" -> å‘ç° {len(posts)} æ¡ç›¸å…³å†…å®¹ï¼Œæ­£åœ¨æ•´ç†...")
        
        organized_content = organize_data(posts, name)
        
        final_report += f"## æ¥æºï¼š{name}\n{organized_content}\n\n---\n\n"

    for name, url in web_sources.items():
        # ç”Ÿæˆç½‘é¡µæˆªå›¾æˆ– PDF
        snapshot_path = f"data/{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
        capture_web_screenshot_png(url, snapshot_path)

        pdf_path = f"data/{name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pdf"
        capture_web_pdf(url, pdf_path)

    for name, url in web_sources.items():
        posts = fetch_web_content(url)
        if posts: # åªæœ‰æŠ“å–æˆåŠŸæ‰å¤„ç†
            print(f" -> æˆåŠŸè·å–ç½‘é¡µå†…å®¹ï¼Œæ­£åœ¨æ•´ç†...")
            organized_content = organize_data(posts, name)
            final_report += f"## æ¥æºï¼š{name} (Web)\n{organized_content}\n\n---\n\n"
    
    # æ‰“å°æœ€ç»ˆæŠ¥å‘Šï¼Œæˆ–è€…å¯ä»¥æ”¹ä¸ºå‘é€é‚®ä»¶/ä¿å­˜ä¸º Markdown æ–‡ä»¶
    print("\n" + "="*30 + " æœ€ç»ˆæŠ¥å‘Š " + "="*30 + "\n")
    print(final_report)