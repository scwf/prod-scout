"""
llm_organizer.py - OrganizerStage for Native Python Pipeline.
"""
import json
import time
from concurrent.futures import ThreadPoolExecutor
from queue import Queue

from openai import OpenAI

from common import setup_logger, _tid

logger = setup_logger("llm_organizer")

def organize_single_post(post, source_name, llm_client, llm_config, max_retries=3, retry_delay=3):
    """
    è°ƒç”¨ LLM å¯¹å•ç¯‡æ–‡ç« è¿›è¡Œæ ‡å‡†åŒ–æ•´ç†ï¼Œè¿”å› JSON ç»“æ„åŒ–æ•°æ®
    
    å‚æ•°:
        post: dict - æ–‡ç« æ•°æ®
        source_name: str - æ¥æºåç§°
        max_retries: int - æœ€å¤§é‡è¯•æ¬¡æ•° (é»˜è®¤ 3)
        retry_delay: int - é‡è¯•é—´éš”ç§’æ•° (é»˜è®¤ 3)
    
    è¿”å›:
        dict: åŒ…å« date, event, key_info, link, detail, category, domain, source_name å­—æ®µ
        None: å¦‚æœæ˜¯çº¯å¹¿å‘Šæˆ–æ— å®è´¨å†…å®¹
    """
    content = post['content']
    
    prompt = f"""
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ Data & AI é¢†åŸŸæƒ…æŠ¥åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰ 10 å¹´è¡Œä¸šç»éªŒã€‚
ä½ çš„ä¸“é•¿åŒ…æ‹¬ï¼šå¤§æ¨¡å‹æŠ€æœ¯ã€AI/æ•°æ®å¹³å°æ¡†æ¶ã€æ™ºèƒ½ä½“åº”ç”¨ã€è¡Œä¸šAIè½åœ°ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å¯¹åŸå§‹ä¿¡æ¯è¿›è¡Œç»“æ„åŒ–æ•´ç†ï¼Œæ•´ç†åçš„æ•°æ®å°†ç”¨äºData & AIäº§å“åˆ†æã€è¡Œä¸šæ´å¯Ÿå’Œå†³ç­–æ”¯æŒã€‚

è¯·å¯¹ä»¥ä¸‹æ¥è‡ªã€{source_name}ã€‘çš„æ–‡ç« è¿›è¡Œæ ‡å‡†åŒ–æ•´ç†ï¼Œè¾“å‡ºä¸º JSON æ ¼å¼ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºï¼š

EXAMPLE JSON OUTPUT:
{{
    "event": "OpenAIå‘å¸ƒGPT-5",
    "key_info": "1. æ”¯æŒå¤šæ¨¡æ€<br>2. ä¸Šä¸‹æ–‡100ä¸‡tokens",
    "detail": "OpenAIå®£å¸ƒå‘å¸ƒGPT-5ï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å¼ºå¤§çš„è¯­è¨€æ¨¡å‹...",
    "category": "æŠ€æœ¯å‘å¸ƒ",
    "domain": "å¤§æ¨¡å‹æŠ€æœ¯å’Œäº§å“",
    "quality_score": 5,
    "quality_reason": "é‡å¤§äº§å“å‘å¸ƒï¼ŒåŒ…å«å…³é”®æŠ€æœ¯å‚æ•°"
}}

å„å­—æ®µè¯´æ˜ï¼š
- **event**: ç®€ç»ƒæ¦‚æ‹¬å‘ç”Ÿäº†ä»€ä¹ˆï¼ˆæ ‡é¢˜/æ ¸å¿ƒåŠ¨ä½œï¼‰ï¼Œåœ¨åŸå§‹æ ‡é¢˜è¶³å¤Ÿæè¿°äº‹ä»¶çš„æƒ…å†µä¸‹å°½å¯èƒ½é‡ç”¨åŸå§‹æ ‡é¢˜æ¥æè¿°äº‹ä»¶
- **key_info**: æå– 1-5 ç‚¹æ ¸å¿ƒç»†èŠ‚ï¼Œç”¨ <br> åˆ†éš”ï¼Œä½œä¸ºä¸€æ®µå­—ç¬¦ä¸²
- **detail**: è‹¥åŸæ–‡æ˜¯Xçš„æ¨æ–‡ï¼Œåˆ™ä¿ç•™åŸå§‹æ¨æ–‡å†…å®¹ï¼›è‹¥åŸæ–‡ä¸é•¿ä¸”å¯è¯»æ€§è‰¯å¥½ä¹Ÿç›´æ¥è¾“å‡ºåŸæ–‡ï¼›å…¶ä»–æƒ…å†µåˆ™å¯¹åŸå§‹å†…å®¹è¿›è¡Œæ ¼å¼ä¼˜åŒ–ï¼ˆæ¯”å¦‚å»æ‰HTMLæ ‡ç­¾ï¼‰ï¼Œç»“æ„åŒ–æ•´ç†è¾“å‡ºä¸ºä¸€æ®µå¯¹åŸæ–‡çš„è¯¦ç»†æè¿°ï¼Œè¦æ±‚å°½å¯èƒ½æŠŠåŸæ–‡çš„è„‰ç»œæ¢³ç†æ¸…æ¥šï¼Œä¸è¦è¿‡äºæ¦‚æ‹¬å’Œç®€ç•¥
- **category**: äº‹ä»¶åˆ†ç±»æ ‡ç­¾ï¼Œä»ä»¥ä¸‹é€‰æ‹©ä¸€ä¸ªï¼šæŠ€æœ¯å‘å¸ƒã€äº§å“åŠ¨æ€ã€è§‚ç‚¹åˆ†äº«ã€å•†ä¸šèµ„è®¯ã€æŠ€æœ¯æ´»åŠ¨ã€å®¢æˆ·æ¡ˆä¾‹ã€å¹¿å‘Šæ‹›è˜ã€å…¶ä»–
- **domain**: æ‰€å±é¢†åŸŸæ ‡ç­¾ï¼Œå¿…é¡»ä»ä»¥ä¸‹é€‰æ‹©ä¸€ä¸ªï¼šå¤§æ¨¡å‹æŠ€æœ¯å’Œäº§å“ã€æ•°æ®å¹³å°å’Œæ¡†æ¶ã€AIå¹³å°å’Œæ¡†æ¶ã€æ™ºèƒ½ä½“å¹³å°å’Œæ¡†æ¶ã€ä»£ç æ™ºèƒ½ä½“ï¼ˆIDEï¼‰ã€æ•°æ®æ™ºèƒ½ä½“ã€è¡Œä¸šæˆ–é¢†åŸŸæ™ºèƒ½ä½“ã€å…·èº«æ™ºèƒ½ã€å…¶ä»–
- **quality_score**: å†…å®¹è´¨é‡è¯„åˆ†(1-5åˆ†)ï¼Œè¯„åˆ†æ ‡å‡†ï¼š
  - 5åˆ†(é«˜ä»·å€¼): æœ‰é‡è¦æ•°æ®ã€æ·±åº¦æ´å¯Ÿã€ç‹¬å®¶ä¿¡æ¯ã€é‡å¤§äº‹ä»¶å‘å¸ƒ
  - 4åˆ†(å€¼å¾—å…³æ³¨): æœ‰å®è´¨å†…å®¹ã€æœ‰å‚è€ƒä»·å€¼ã€å€¼å¾—è·Ÿè¿›
  - 3åˆ†(ä¸€èˆ¬): ä¿¡æ¯ä¸€èˆ¬ã€å¯ä½œä¸ºèƒŒæ™¯å‚è€ƒ
  - 2åˆ†(ä»·å€¼æœ‰é™): å†…å®¹å•è–„ã€ç¼ºä¹æ·±åº¦ã€ä¿¡æ¯å¯†åº¦ä½
  - 1åˆ†(æ— ä»·å€¼): æ— å®è´¨å†…å®¹ã€çº¯è¥é”€å¹¿å‘Šã€å®Œå…¨ä¸ç›¸å…³
- **quality_reason**: ç®€çŸ­è¯´æ˜è¯„åˆ†ç†ç”±

åŸå§‹æ•°æ®ï¼š
æ ‡é¢˜: {post['title']}
æ—¶é—´: {post['date']}
åŸæ–‡é“¾æ¥: {post['link']}
æ¥æºç±»å‹: {post['source_type']}
å†…å®¹: {content}
è¡¥å……å†…å®¹: {post.get('extra_content', '')}
"""

    # å¸¦é‡è¯•æœºåˆ¶çš„ API è°ƒç”¨
    result_text = None
    finish_reason = None
    
    for attempt in range(max_retries + 1):
        try:
            start_ts = time.time()
            response = llm_client.chat.completions.create(
                model=llm_config.get('llm', 'model'),
                messages=[
                    {"role": "system", "content": "You are a helpful assistant for data organization. Output only valid JSON, no extra text."},
                    {"role": "user", "content": prompt}
                ],
                response_format={'type': 'json_object'}
            )
            elapsed = time.time() - start_ts
            logger.info(f"LLM Response Time: {elapsed:.2f}s for {post['title'][:30]}...")
            
            # è·å–å“åº”å†…å®¹å’Œå®ŒæˆåŸå› 
            result_text = response.choices[0].message.content
            finish_reason = response.choices[0].finish_reason
            
            # å¤„ç† None æˆ–ç©ºå­—ç¬¦ä¸²
            if not result_text or not result_text.strip():
                if attempt < max_retries:
                    logger.warning(f"âš ï¸ [LLM-Empty][{post['title'][:30]}] sleep {retry_delay}s to retry... (Reason: {finish_reason})")
                    time.sleep(retry_delay)
                    continue
                logger.error(f"âŒ [LLM-Fail][{post['title'][:30]}] Empty response after retries.")
                return None
            
            # æˆåŠŸè·å–å“åº”ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
            result_text = result_text.strip()
            break
            
        except Exception as e:
            if attempt < max_retries:
                logger.warning(f"âš ï¸ [LLM-Error][{post['title'][:30]}] {e}. Retrying in {retry_delay}s...")
                time.sleep(retry_delay)
                continue
            # æœ€åä¸€æ¬¡é‡è¯•ä¹Ÿå¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸
            logger.error(f"âŒ [LLM-Fail][{post['title'][:30]}] Final attempt failed: {e}")
            raise
    
    # è§£æ JSON å“åº”
    try:
        result = json.loads(result_text)    
    except json.JSONDecodeError as e:
        logger.error(f"âŒ [JSON-Fail] {post['link']} Parse error: {e}")
        logger.error(f"âŒ [JSON-Fail] {result_text}")
        return None

    # è¡¥å…¨åŸºç¡€å­—æ®µ (å‡å°‘LLMè¾“å‡º)
    result['date'] = post.get('date', '')
    result['link'] = post.get('link', '')
    result['source_name'] = source_name
    
    # æ·»åŠ  extra_content å’Œ extra_urls
    result['extra_content'] = post.get('extra_content', '')
    result['extra_urls'] = post.get('extra_urls', [])

    # Final Success Log
    logger.info(f"ğŸ¤– [Organized] {result.get('domain', 'Unknown')} | Score: {result.get('quality_score')} | {post['title'][:50]}...")

    return result

class OrganizerStage:
    def __init__(self, enrich_queue: Queue, organize_queue: Queue, config):
        self.enrich_queue = enrich_queue
        self.organize_queue = organize_queue
        self.config = config
        self.client = OpenAI(
            api_key=self.config.get('llm', 'api_key'),
            base_url=self.config.get('llm', 'base_url'),
        )
        
        self.max_workers = config.getint('crawler', 'organize_workers', fallback=5)
        self.pool = ThreadPoolExecutor(max_workers=self.max_workers, thread_name_prefix="Organizer")
        self.futures = []

    def start(self):
        """Start consumer workers."""
        logger.info(f"Starting OrganizerStage with {self.max_workers} workers...")
        for _ in range(self.max_workers):
            self.futures.append(
                self.pool.submit(self._worker_loop)
            )

    def stop(self):
        """Graceful shutdown."""
        logger.info("Stopping OrganizerStage... Sending poison pills.")
        for _ in range(self.max_workers):
            self.enrich_queue.put(None)
        
        self.pool.shutdown(wait=True)
        logger.info("OrganizerStage stopped.")

    def _worker_loop(self):
        while True:
            post = self.enrich_queue.get()
            
            if post is None:
                self.enrich_queue.task_done()
                break
            
            try:
                # organize_single_post comes from local module now
                source_name = post.get('source_name', 'Unknown')
                
                # If post is broken or somehow None (integrity check)
                if not post:
                    continue
                    
                result = organize_single_post(
                    post,
                    source_name,
                    llm_client=self.client,
                    llm_config=self.config,
                )
                
                if result:
                    self.organize_queue.put(result)
                else:
                    # Logic: if None returned, it means skip (ad or empty)
                    pass
                    
            except Exception as e:
                logger.error(f"Organizer task failed: {e}")
            finally:
                self.enrich_queue.task_done()
